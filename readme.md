
# ðŸ“˜ Question & MCQ Generator with Evaluation

An interactive application built with **FastAPI**, **LangChain**, **ChatGroq**, and **Streamlit** that allows users to:
- ðŸ“„ Generate questions or MCQs from a backend PDF document.
- ðŸŽ¯ Select difficulty level: Easy, Medium, Hard.
- ðŸ“ Submit answers and receive feedback.
- âœ… Get automatic evaluation and scoring.

---

## ðŸš€ Features

- âœ… **PDF-based document ingestion**
- ðŸŽ“ **Question & MCQ generation** powered by **LLMs (Groq + LangChain)**
- ðŸ”„ **Session-based interaction** with **Streamlit**
- ðŸ“Š **Answer evaluation** with LLM-generated feedback
- â­ **Scoring system** to track performance
- âš™ï¸ **Difficulty selection** (easy, medium, hard)

---

## ðŸ§± Tech Stack

| Layer        | Technology             |
|--------------|------------------------|
| Frontend     | Streamlit              |
| Backend      | FastAPI                |
| LLMs         | ChatGroq (Mixtral / Gemma) |
| Document Parsing | LlamaParse         |
| Prompt Engine | LangChain             |
| Embeddings (Optional) | SentenceTransformers |

---

## ðŸ“‚ Project Structure

```
question-mcq-app/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                  # FastAPI backend app
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ parser.py           # PDF to text using LlamaParse
â”‚       â”œâ”€â”€ question_gen.py     # Question generation using LLM
â”‚       â”œâ”€â”€ mcq_gen.py          # MCQ generation as structured JSON
â”‚       â””â”€â”€ evaluator.py        # Evaluate user answers via LLM
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                  # Streamlit UI for interaction
â”‚
â”œâ”€â”€ document.pdf                # Source content document
â”œâ”€â”€ .env                        # API keys for ChatGroq
â”œâ”€â”€ requirements.txt            # Dependency file
â””â”€â”€ README.md                   # Youâ€™re here
```

---

## ðŸ› ï¸ Setup Instructions

### 1. Clone the repository
```bash
git clone https://github.com/your-username/question-mcq-app.git
cd question-mcq-app
```

### 2. Create a virtual environment
```bash
python -m venv env
source env/bin/activate   # or env\Scripts\activate on Windows
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Add your Groq API key in `.env`
```
InDoc=your_groq_api_key
```

### 5. Add your `document.pdf` in the root directory

---

## âš™ï¸ Running the App

### Start the Backend (FastAPI)
```bash
cd backend
uvicorn app:app --reload
```

### Start the Frontend (Streamlit)
```bash
cd ../frontend
streamlit run app.py
```

Open [http://localhost:8501](http://localhost:8501) in your browser.

---

## ðŸ§ª Example Use Case

> ðŸ“˜ Select: "Generate MCQs"  
> ðŸ§  Choose: Difficulty = *Medium*  
> âœï¸ Answer questions  
> ðŸ” Click â€œEvaluate My Answersâ€  
> ðŸŽ¯ View your score & correct answers with helpful feedback

---

## âœ… Sample API Endpoints

- `POST /generate_questions`:  
  Body â†’ `{ "num_questions": 5, "difficulty": "medium" }`

- `POST /generate_mcqs`:  
  Body â†’ `{ "num_questions": 5, "difficulty": "hard" }`

- `POST /evaluate`:  
  Body â†’ `{ "user_answers": { "Q1": "B", "Q2": "A", ... } }`

---

## ðŸ§  Powered By

- [LangChain](https://github.com/langchain-ai/langchain)
- [Groq API](https://console.groq.com/)
- [LlamaParse](https://github.com/run-llama/llama-parse)
- [Streamlit](https://streamlit.io/)
- [FastAPI](https://fastapi.tiangolo.com/)

---

## ðŸ“Œ Future Improvements

- âœ… User authentication
- ðŸ“Š Admin dashboard with leaderboard
- ðŸ§  Explanation for each correct/incorrect answer
- ðŸ”„ Allow user-uploaded PDFs
- ðŸ§¾ Export results as PDF or CSV

---

## ðŸ“„ License

This project is licensed under the [MIT License](LICENSE).
